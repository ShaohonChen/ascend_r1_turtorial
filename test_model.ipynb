{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_path=\"/root/projects/ascend_r1_turtorial/output/qwen-3b-r1-coundown\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "def generate_r1_prompt(numbers, target):\n",
    "    \"\"\"\n",
    "    生成 R1 Countdown 游戏提示词\n",
    "\n",
    "    参数:\n",
    "        numbers (list[int]): 数字列表\n",
    "        target (int): 目标值\n",
    "    返回:\n",
    "        dict: 生成的一个数据样本\n",
    "    \"\"\"\n",
    "    # 定义提示词前缀\n",
    "    r1_prefix = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"使用给定的数字 {numbers}，创建一个等于 {target} 的方程。你可以使用基本算术运算（+、-、*、/）一次或多次，但每个数字只能使用一次。在 <think> </think> 标签中展示你的思考过程，并在 <answer> </answer> 标签中返回最终方程，例如 <answer> (1 + 2) / 3 </answer>。在 <think> 标签中逐步思考。\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"让我们逐步解决这个问题。\\n<think>\",  # 结尾使用 `<think>` 促使模型开始思考\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    return  tokenizer.apply_chat_template(\n",
    "            r1_prefix, tokenize=False, continue_final_message=True)\n",
    "\n",
    "text=generate_r1_prompt([19,5,3,],7)\n",
    "print(text)\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import AutoModelForCausalLM\n",
    "device = \"cuda:3\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=device\n",
    ")\n",
    "\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=1024,\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train_r1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
